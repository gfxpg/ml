{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caffe2 model\n",
    "\n",
    "I'm going to explore _ResNet50_, an official model for which can be obtained as\n",
    "```\n",
    "curl -LO https://raw.githubusercontent.com/caffe2/models/master/resnet50/predict_net.pbtxt\n",
    "```\n",
    "\n",
    "This file defines network operations, but omits tensor shapes. This information is stored separately, along with pre-trained parameters:\n",
    "\n",
    "```\n",
    "curl -LO https://github.com/caffe2/models/raw/master/resnet50/init_net.pb\n",
    "```\n",
    "\n",
    "The file is quite large (> 100MB), and when loaded as-is, it can bring the Python kernel to its knees. Hence we remove all parameters from the protobuf message definition before deserializing it:\n",
    "\n",
    "```\n",
    "curl -LO https://raw.githubusercontent.com/caffe2/caffe2/master/caffe2/proto/caffe2.proto\n",
    "sed -i '/floats\\|float_data\\|int32_data\\|byte_data\\|string_data\\|double_data\\|int64_data/d' caffe2.proto\n",
    "```\n",
    "\n",
    "Finally, we compile the definition to a Python file (you need the [protocol compiler](https://github.com/google/protobuf#protocol-compiler-installation) installed on your system):\n",
    "```\n",
    "protoc -I=. --python_out=. caffe2.proto\n",
    "```\n",
    "\n",
    "For any given operation, it's sufficient to know the number of output channels -- spatial dimensions can be computed from kernel size and stride/padding information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe2_pb2\n",
    "\n",
    "with open('init_net.pb', 'rb') as f:\n",
    "  caffe2_tensor_defs = caffe2_pb2.NetDef()\n",
    "  caffe2_tensor_defs.ParseFromString(f.read())\n",
    "\n",
    "# We're only interested in weight shapes (ending with _w)\n",
    "tensor_out_channels = {o.output[0]: o.arg[0].ints[0] for o in caffe2_tensor_defs.op if o.output[0].endswith('_w')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.protobuf.text_format as pb_text_format\n",
    "\n",
    "with open('predict_net.pbtxt') as f:\n",
    "  caffe2_model_def = pb_text_format.Parse(f.read(), caffe2_pb2.NetDef())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seemingly staightforward way to compute spatial dimensions is to feed the output shape of the previous op to the succeeding op. This wouldn't work in the context of ResNet, however, due to the network topology featuring shortcut connections; hence we use a dictionary of operation name <-> output dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def compute_out_dimensions(in_h, in_w, kernel_h, kernel_w, padding, stride):\n",
    "  out_h = floor((in_h - kernel_h + 2 * (padding or 0)) / (stride or 1)) + 1\n",
    "  out_w = floor((in_w - kernel_w + 2 * (padding or 0)) / (stride or 1)) + 1\n",
    "  return out_h, out_w\n",
    "\n",
    "def parse_caffe2_op(op, in_h, in_w, in_channels):\n",
    "  args = {a.name: a.i for a in op.arg}\n",
    "  padding = args.get('pad')\n",
    "  stride = args.get('stride')\n",
    "  kernel_size = args.get('kernel')\n",
    "  weights_tensor = next((inp for inp in op.input if inp.endswith('_w')), None)\n",
    "  out_channels = tensor_out_channels[weights_tensor] if weights_tensor else in_channels\n",
    "  out_h, out_w = compute_out_dimensions(in_h, in_w, kernel_size, kernel_size, padding, stride) if kernel_size else [in_h, in_w]\n",
    "  \n",
    "  description =  [op.type, in_channels, out_channels, kernel_size, kernel_size, padding, stride, out_h, out_w]\n",
    "\n",
    "  return (out_h, out_w, out_channels, description)\n",
    "\n",
    "descriptions = []\n",
    "dimensions = {'gpu_0/data': (224, 224, 3)}\n",
    "\n",
    "for op in caffe2_model_def.op:\n",
    "  input_h, input_w, input_channels = dimensions[op.input[0]]\n",
    "  output_h, output_w, output_channels, descr = parse_caffe2_op(op, input_h, input_w, input_channels)\n",
    "  dimensions[op.output[0]] = (output_h, output_w, output_channels)\n",
    "  descriptions.append(descr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we convert model descriptions to CSV to analyze them later in a spreadsheet form. We also translate operation names so as to stay consistent between Caffe2 and TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_names = {'Conv': 'Conv', 'SpatialBN': 'BatchNorm', 'Relu': 'Relu', 'MaxPool': 'MaxPool', 'Sum': 'Sum',\n",
    "            'AveragePool': 'AveragePool', 'FC': 'FullyConnected', 'Softmax': 'Softmax'}\n",
    "\n",
    "def translate_op_name(descr):\n",
    "  descr[0] = op_names[descr[0]]\n",
    "  return descr\n",
    "\n",
    "def stringify(val):\n",
    "  return str(val) if val is not None else ''\n",
    "\n",
    "descriptions = [','.join(translate_op_name(list(map(stringify, descr)))) for descr in descriptions]\n",
    "for d in descriptions: print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow model\n",
    "\n",
    "I have a graph definition file already prepared -- copied from a checkpoint -- for the same model (_ResNet50_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with open('graph.pbtxt') as f:\n",
    "  graph_def = pb_text_format.Parse(f.read(), tf.GraphDef())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output shape information is present in the graph definition, so we don't have to hunt for additional files like with Caffe2. Kernel shape is not stated explicitly, but we can extract it from weight tensor shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = ['Conv2D', 'FusedBatchNorm', 'MaxPool', 'Relu', 'Add']\n",
    "op_names = {'Conv2D': 'Conv', 'FusedBatchNorm': 'BatchNorm', 'Relu': 'Relu', 'MaxPool': 'MaxPool', 'Add': 'Sum'}\n",
    "\n",
    "def extract_conv_param_hw(node, graph_def):\n",
    "  param_node_name = next(name for name in node.input if name.endswith('read'))\n",
    "  return var_dimensions[param_node_name][0:2]\n",
    "\n",
    "def extract_output_dims(node):\n",
    "  return [d.size for d in node.attr['_output_shapes'].list.shape[0].dim]\n",
    "\n",
    "def describe_tf_node(node, in_channels):\n",
    "  _, out_h, out_w, out_channels = extract_output_dims(node)\n",
    "  \n",
    "  kernel_h, kernel_w = (node.attr['ksize'].list.i[1:3] if 'ksize' in node.attr\n",
    "    else extract_conv_param_hw(node, graph_def) if node.op == 'Conv2D'\n",
    "    else [None] * 2)\n",
    "\n",
    "  stride = node.attr['strides'].list.i[1] if node.attr['strides'] and len(node.attr['strides'].list.i) > 0 else None # assuming vertical stride = horizontal stide\n",
    "  \n",
    "  return (out_channels, list(map(stringify,\n",
    "    [op_names[node.op], in_channels, out_channels, kernel_h, kernel_w, None, stride, out_h, out_w])))\n",
    "\n",
    "var_dimensions = {n.name: extract_output_dims(n) for n in graph_def.node if n.name.endswith('read')}\n",
    "\n",
    "nodes = [n for n in graph_def.node if n.op in ops and n.name.startswith('v/tower_0/cg')]\n",
    "descriptions = []\n",
    "output_channels_per_input = {nodes[0].input[0]: 3}\n",
    "for n in nodes:\n",
    "  out_channels, descr = describe_tf_node(n, output_channels_per_input[n.input[0]])\n",
    "  output_channels_per_input[n.name] = out_channels\n",
    "  descriptions.append(descr)\n",
    "\n",
    "for d in descriptions: print(','.join(d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
